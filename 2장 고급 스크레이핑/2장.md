## 2장 고급 스크레이핑

`목표`  자바스크립트를 사용한 사이트, 로그인이 필요한 사이트에서 데이터를 추출할 때 필요한 기법 알아보기



### 2-1 로그인이 필요한 사이트

> ### HTTP

* 브라우저에서 서버로 **요청**하고, 서버에서 브라우저로 **응답**할 때 어떻게 할 것인지를 나타내는 규약
* 기본적으로 무상태 통신이다.
  * `무상태통신 ` : 같은 URL에 여러번 접근해도 같은 데이터를 돌려주는 통신, 즉 이전에 어떤 데이터를 가져갔는지 등에 대한 정보를 전혀 저장하지 않는 통신



> ### 쿠키

* 웹 브라우저를 통해 사이트에 방문하는 사람의 컴퓨터에 **일시적**으로 데이터를 저장하는 기능
* <u>무상태 HTTP 통신으로는 회원제 사이트를 만들 수 없다.</u> 그래서 웹 브라우저에 쿠키라는 구조가 추가되었다.
* 1개의 쿠키에 저장할 수 있는 데이터의 크기가 4096바이트로 **제한**되어있고, 쿠키는 HTTP 통신 헤더를 통해 읽고 쓸 수 있다. 따라서 방문자 또는 확인자 측에서 원하는 대로 **변경할 수 있다.**
* 그래서 변경하면 문제가 생길 수 있는 비밀번호 등의 비밀 정보를 저장하는데 사용하기에는 좋지 않다.



> ### 세션

* 그렇기 때문에 **세션**이라는 구조를 사용한다.
* 세션도 쿠키를 사용해 데이터를 저장한다. 하지만 쿠키에는 방문자 고유 ID만 저장하고 실제로 모든 데이터는 웹 서버에 저장해서 쿠키와는 다르게 **저장할 수 있는 데이터에 제한이 없다.**
* HTTP 통신은 무상태 통신이지만 세션을 이용하면 쿠키에 기록돼 있는 고유 ID를 키로 사용해 상태 변수로 확인할 수 있고, 통신을 계속해서 진행하는 것 같은 상태 유지 통신을 구현할 수 있다.



> ### requests

* 이 패키지를 이용하여 쉽게 쿠키를 이용한 접근을 할 수 있다.

  (다만 프로그램이 쉽게 로그인할 수 없게 보안적으로 구성한 네이버와 같은 포털 사이트 등은 이 방법이 불가능)

* F12 -> Network -> Doc -> Preserve log체크표시 -> login_proc.php -> Headers -> Form Data 에서 ID와 Password 확인 가능
* requests.session을 이용하면 쿠키를 사용하는 회원제 사이트에 로그인 할 수 있다.
* import requests를 통해 requests 모듈을 읽어들어야 사용 가능
* HTTP에서 사용하는 GET, POST, PUT, DELETE, HEAD 등의 요청을 위한 메서드도 있다.
* 그리고 GET, POST 등의 리턴값에 있는 text와 content 속성을 참조하면 내부의 데이터를 확인할 수 있다.



?!

**wb** : write and binary - png file

**rb** : read and binary - jpg file





### 2-2 웹 브라우저를 이용한 스크레이핑

> ### Selenium

* 웹 브라우저를 원격 조작할 때 사용하는 도구
* 일반적으로 웹 어플리케이션 테스트를 자동화할 때 사용하지만 스크레이핑할 때도 유용하게 사용할 수 있다.
* 자동으로 URL을 열고 클릭할 수 있으며, 스크롤하거나, 문자를 입력하는 등의 다양한 조작을 자동화할 수 있다.
* 또한 화면을 캡쳐해서 이미지로 저장하거나 HTML의 특정 부분을 꺼내는 것도 가능하다.
* Selenium import 할 때는 기본적으로 from selenium import Webdriver 사용
* execute_script() 메서드를 사용하면 자바스크립트 코드를 실행할 수 있다.



> ### PhantomJS

* 화면 없이 명령줄에서 사용할 수 있는 웹 브라우저
* 레이아웃 엔진으로 애플에서 만든 웹 브라우저인 사파리의 렌더링 엔진 WebKit를 사용한다.
* 이것을 이용하여 명령줄에서 웹 브라우저를 조작할 수 있어 브라우저 내부에 출력되는 데이터를 추출하거나 스크린샷을 찍을 수 있다.





### 2-3 웹 API로 데이터 추출하기

> ### API(Application Programming Interface)

* 어떤 프로그램 기능을 외부의 프로그램에서 호출해서 사용할 수 있게 만든 것을 의미한다.
* 간단하게 서로 다른 프로그램이 기능을 공유할 수 있게 절차와 규약을 정의한 것



> ### 웹 API

* 클라이언트 프로그램은 API를 제공하는 서버에 HTTP 요청을 보내면 서버가 이러한 요청을 기반으로 XML 또는 JSON 형식 등으로 응답한다.
* 두 형식 모두 계층 구조를 가지고 있으므로 복잡한 데이터를 표현할 수 있다.
* **제공하는 이유**는 선의의 의미도 있지만 웹 API를 미리 제공해서 서버의 부담을 줄이거나 상품을 알리고 구매할 기회를 더 주기위해서도 있다.
* **단점** : 제공자의 사정으로 없어지거나 사양 변경이 일어날 수 있다. (비일비재)





### 2-4 cron을 이용한 정기적인 크롤링

> 주식, 환율, 날씨 예보와 같이 주기적으로 변경되는 데이터를 사용할 때는 정기적으로 데이터를 크롤링해야한다.

> 윈도우에서는 작업 스케줄러라는 기능이 있고 macOS/리눅스에서는 크론이라는 데몬 프로세스를 사용해 정기적으로 데이터 크롤링을 할 수 있다.



> ### Cron의 기능

* 데이터 수집과 같은 애플리케이션에서 필요한 정기적인 처리
* 로그, 백업과 같은 시스템에서 필요한 정기적인 처리
* 시스템이 제대로 동작하고 있는지 정기적으로 감시하는 처리